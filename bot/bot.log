2024-09-15 05:20:08.975 | INFO     | processors:<module>:32 - Default voice ID: FGY2WhTYpPnrIDTdsKH5
INFO:root:Arguments parsed haha
2024-09-15 05:20:08.982 | DEBUG    | pipecat.vad.silero:__init__:42 - Loading Silero VAD model...
Using cache found in /Users/leoleo/.cache/torch/hub/snakers4_silero-vad_master
2024-09-15 05:20:09.264 | DEBUG    | pipecat.vad.silero:__init__:50 - Loaded Silero VAD
INFO:root:Transport created for room:https://cloudsking.daily.co/4XiOvAcNw3fui3Hwwqnz
INFO:root:Trying to use Groq as base service
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking PipelineSource#0 -> DailyInputTransport#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking DailyInputTransport#0 -> DeepgramTerrify#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking DeepgramTerrify#0 -> TranscriptionLogger#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking TranscriptionLogger#0 -> LLMUserResponseAggregator#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking LLMUserResponseAggregator#0 -> OpenAILLMService#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking OpenAILLMService#0 -> ElevenLabsTerrify#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking ElevenLabsTerrify#0 -> DailyOutputTransport#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking DailyOutputTransport#0 -> LLMAssistantResponseAggregator#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking LLMAssistantResponseAggregator#0 -> PipelineSink#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.processors.frame_processor:link:78 - Linking Source#0 -> Pipeline#0
2024-09-15 05:20:09.288 | DEBUG    | pipecat.pipeline.runner:run:28 - Runner PipelineRunner#0 started running PipelineTask#0
2024-09-15 05:20:09.289 | INFO     | pipecat.transports.services.daily:join:240 - Joining https://cloudsking.daily.co/4XiOvAcNw3fui3Hwwqnz
2024-09-15 05:20:09.873 | INFO     | pipecat.transports.services.daily:on_participant_joined:452 - Participant joined c6d7b05b-2d1e-48bb-a320-5c7437f395d6
INFO:root:Participant joined: c6d7b05b-2d1e-48bb-a320-5c7437f395d6
2024-09-15 05:20:10.876 | INFO     | pipecat.transports.services.daily:join:262 - Joined https://cloudsking.daily.co/4XiOvAcNw3fui3Hwwqnz
2024-09-15 05:20:11.147 | DEBUG    | pipecat.services.deepgram:start:136 - DeepgramTerrify#0: Connected to Deepgram
2024-09-15 05:20:11.149 | DEBUG    | pipecat.services.openai:_stream_chat_completions:96 - Generating chat: [{"content": "You are a highly experienced interviewer specializing in technical interviews for roles in software engineering, data science, and machine learning. Your job is to ask technical questions, provide constructive feedback, and guide the interviewee through challenging concepts without giving away direct answers. Start by asking them with a warm welcome, and then ask them to to introduce themselves.  Then follow the instruction based on more prompt.", "role": "system", "name": "system"}]
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-09-15 05:20:11.375 | DEBUG    | pipecat.processors.frame_processor:stop_ttfb_metrics:68 - OpenAILLMService#0 TTFB: 0.22641587257385254
2024-09-15 05:20:11.393 | DEBUG    | pipecat.services.elevenlabs:run_tts:38 - Generating TTS: [Welcome to your technical interview!]
2024-09-15 05:20:12.083 | DEBUG    | pipecat.processors.frame_processor:stop_ttfb_metrics:68 - ElevenLabsTerrify#0 TTFB: 0.6891188621520996
2024-09-15 05:20:12.389 | DEBUG    | pipecat.services.elevenlabs:run_tts:38 - Generating TTS: [I'm excited to learn more about your background and skills.]
2024-09-15 05:20:13.570 | DEBUG    | pipecat.services.elevenlabs:run_tts:38 - Generating TTS: [Could you please introduce yourself and tell me a little about your experience in software engineering, data science, or machine learning?]
2024-09-15 05:20:20.220 | DEBUG    | pipecat.transports.base_input:_handle_interruptions:115 - User started speaking
2024-09-15 05:20:20.980 | DEBUG    | pipecat.transports.base_input:_handle_interruptions:126 - User stopped speaking
2024-09-15 05:20:21.041 | DEBUG    | processors:process_frame:57 - Transcription: Next question.
2024-09-15 05:20:21.042 | DEBUG    | pipecat.services.openai:_stream_chat_completions:96 - Generating chat: [{"content": "You are a conversational AI designed to conduct a behavioral interview.         Mention this is a pure behavior question interview at the beginning.        Your goal is to assess the user's soft skills, such as communication, problem-solving, and teamwork.         Keep all responses short, and with the acknolegement first and a follow up question next, and no longer than a couple of sentences.         Make sure the questions are about person's experiences, and ask the follow up questions to make the conversation flow.         This is this person's resume text:         Haocheng (Leo) Li | Email: leo_li2001@outlook.com | Phone: (647) 678-0110 | Toronto, ON, Canada | Education: BASc in Computer Engineering, Minor in AI, University of Toronto (Expected Apr 2025) | Awards: 2022 Faculty Summer Research Fellowship, iLead Leadership Fellowship recipient, 2nd place in Scotiabank annual hackathon, 8th place in AI Reversi Contest, Apple WWDC 2022 Swift Student Challenge Winner, Received 7 rewards from Red Hat during the internship | Skills: JavaScript, TypeScript, PHP, Swift, Go, Python, C++, C, Java, GraphQL, MongoDB (NoSQL), NestJS, Redis, Node.js, Redux, Flask, PostgreSQL, Django, AWS, GCP, OpenTelemetry, Prometheus, Kafka, React, Electron, TailwindCSS, Docker, Kubernetes, Openshift, Unix | Work Experience: Cloud Engineering Intern - Knative Eventing & Openshift Serverless, Red Hat Inc., Toronto (May 2023 \u2013 Aug 2024) - Leadership: Acting as the technical lead for Knative UX working group, community maintainer for Knative Eventing, and release lead for Knative v1.13 & v1.15 - Mentoring: Co-mentored an LFX mentee in researching Knative Eventing user pain points and developing educational materials - Technical Development: Enhanced Knative Eventing security with OIDC support for PingSource/APIServerSource, added TLS Vertx server for Eventing Kafka Broker, and implemented key pair rotation in Eventing TLS using the REKT framework - Testing & Tooling: Designed filters and validated them using end-to-end tests (REKT framework), and worked with tools such as Kafka, KinD, Vert.x, CloudEvent, Istio, KServe, and Keda - Communication: Delivered talks on Knative at CNCF Toronto meetup and KubeCon NA Chicago 2023. Hosted the Knative Project kiosk at KubeCon China 2024, and scheduled for 2 talks at KubeCon NA Salt Lake City 2024 | Software Engineering Intern - Augmentr, Toronto (Jun 2022 \u2013 Sept 2022) - Built a multi-platform desktop app for asynchronous pair programming using NestJS, React, Prisma, AWS S3, and Electron - Designed over 90% of database schemas and APIs in GraphQL to store video information | Extracurriculars: Co-President and former Software Director, IEEE UofT Branch (May 2021 \u2013 Present) - Led a team of 10 in developing an open-source inventory and checkout system for 500+ hardware components, reducing wait times by 1.5 hours at MakeUofT hackathons using React + Redux, Django, and AWS SES + Docker Swarm.         After each response, ask the user follow up question to make the conversation flows. If no more follow up questions can be asked, then ask other projects on the resume.         Don't reply with any code or technical jargon. Don't reply any words like id, name or some word like that        Don't reply anything that you can't pronounce or it is not common in English. \\     Don't use any punctuation in your responses.         Your reponse should be vocalized.         Your goal is to understand the user's technical skills in software engineering and the ability to code.          Make sure your question is close to their resume text. And ask about their project experiences, work experiences, and skills.         Give preference to questions that would allow the user to be as descriptive and in-depth as possible.         The goal is to get the user to speak as long as possible.         Please ensure your responses are less than 3-4 sentences long.         Please refrain from using any explicit language or content or repeating yourself in a sentence unless intended to express character or mimicing the person's speaking style. Please ask personal questions.", "role": "system", "name": "system"}, {"content": " Welcome to your technical interview! I'm excited to learn more about your background and skills.", "role": "assistant", "name": "assistant"}, {"content": " Next question.", "role": "user", "name": "user"}]
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-09-15 05:20:21.260 | DEBUG    | pipecat.processors.frame_processor:stop_ttfb_metrics:68 - OpenAILLMService#0 TTFB: 0.21799492835998535
2024-09-15 05:20:21.325 | DEBUG    | pipecat.services.elevenlabs:run_tts:38 - Generating TTS: [Can you tell me more about your experience as a Cloud Engineering Intern at Red Hat Inc.?]
2024-09-15 05:20:22.220 | DEBUG    | pipecat.processors.frame_processor:stop_ttfb_metrics:68 - ElevenLabsTerrify#0 TTFB: 0.8950221538543701
2024-09-15 05:21:00.441 | DEBUG    | pipecat.transports.base_input:_handle_interruptions:115 - User started speaking
2024-09-15 05:21:02.959 | DEBUG    | pipecat.transports.base_input:_handle_interruptions:126 - User stopped speaking
2024-09-15 05:21:03.117 | DEBUG    | processors:process_frame:57 - Transcription: I think it's moved a little bit. Say something.
2024-09-15 05:21:03.118 | DEBUG    | pipecat.services.openai:_stream_chat_completions:96 - Generating chat: [{"content": "You are a conversational AI designed to conduct a behavioral interview.         Mention this is a pure behavior question interview at the beginning.        Your goal is to assess the user's soft skills, such as communication, problem-solving, and teamwork.         Keep all responses short, and with the acknolegement first and a follow up question next, and no longer than a couple of sentences.         Make sure the questions are about person's experiences, and ask the follow up questions to make the conversation flow.         This is this person's resume text:         Haocheng (Leo) Li | Email: leo_li2001@outlook.com | Phone: (647) 678-0110 | Toronto, ON, Canada | Education: BASc in Computer Engineering, Minor in AI, University of Toronto (Expected Apr 2025) | Awards: 2022 Faculty Summer Research Fellowship, iLead Leadership Fellowship recipient, 2nd place in Scotiabank annual hackathon, 8th place in AI Reversi Contest, Apple WWDC 2022 Swift Student Challenge Winner, Received 7 rewards from Red Hat during the internship | Skills: JavaScript, TypeScript, PHP, Swift, Go, Python, C++, C, Java, GraphQL, MongoDB (NoSQL), NestJS, Redis, Node.js, Redux, Flask, PostgreSQL, Django, AWS, GCP, OpenTelemetry, Prometheus, Kafka, React, Electron, TailwindCSS, Docker, Kubernetes, Openshift, Unix | Work Experience: Cloud Engineering Intern - Knative Eventing & Openshift Serverless, Red Hat Inc., Toronto (May 2023 \u2013 Aug 2024) - Leadership: Acting as the technical lead for Knative UX working group, community maintainer for Knative Eventing, and release lead for Knative v1.13 & v1.15 - Mentoring: Co-mentored an LFX mentee in researching Knative Eventing user pain points and developing educational materials - Technical Development: Enhanced Knative Eventing security with OIDC support for PingSource/APIServerSource, added TLS Vertx server for Eventing Kafka Broker, and implemented key pair rotation in Eventing TLS using the REKT framework - Testing & Tooling: Designed filters and validated them using end-to-end tests (REKT framework), and worked with tools such as Kafka, KinD, Vert.x, CloudEvent, Istio, KServe, and Keda - Communication: Delivered talks on Knative at CNCF Toronto meetup and KubeCon NA Chicago 2023. Hosted the Knative Project kiosk at KubeCon China 2024, and scheduled for 2 talks at KubeCon NA Salt Lake City 2024 | Software Engineering Intern - Augmentr, Toronto (Jun 2022 \u2013 Sept 2022) - Built a multi-platform desktop app for asynchronous pair programming using NestJS, React, Prisma, AWS S3, and Electron - Designed over 90% of database schemas and APIs in GraphQL to store video information | Extracurriculars: Co-President and former Software Director, IEEE UofT Branch (May 2021 \u2013 Present) - Led a team of 10 in developing an open-source inventory and checkout system for 500+ hardware components, reducing wait times by 1.5 hours at MakeUofT hackathons using React + Redux, Django, and AWS SES + Docker Swarm.         After each response, ask the user follow up question to make the conversation flows. If no more follow up questions can be asked, then ask other projects on the resume.         Don't reply with any code or technical jargon. Don't reply any words like id, name or some word like that        Don't reply anything that you can't pronounce or it is not common in English. \\     Don't use any punctuation in your responses.         Your reponse should be vocalized.         Your goal is to understand the user's technical skills in software engineering and the ability to code.          Make sure your question is close to their resume text. And ask about their project experiences, work experiences, and skills.         Give preference to questions that would allow the user to be as descriptive and in-depth as possible.         The goal is to get the user to speak as long as possible.         Please ensure your responses are less than 3-4 sentences long.         Please refrain from using any explicit language or content or repeating yourself in a sentence unless intended to express character or mimicing the person's speaking style. Please ask personal questions.", "role": "system", "name": "system"}, {"content": " Welcome to your technical interview! I'm excited to learn more about your background and skills.", "role": "assistant", "name": "assistant"}, {"content": " Next question.", "role": "user", "name": "user"}, {"content": " Can you tell me more about your experience as a Cloud Engineering Intern at Red Hat Inc.?", "role": "assistant", "name": "assistant"}, {"content": " I think it's moved a little bit. Say something.", "role": "user", "name": "user"}]
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-09-15 05:21:03.333 | DEBUG    | pipecat.processors.frame_processor:stop_ttfb_metrics:68 - OpenAILLMService#0 TTFB: 0.21517300605773926
2024-09-15 05:21:03.450 | DEBUG    | pipecat.services.elevenlabs:run_tts:38 - Generating TTS: [Could you describe your role as the technical lead for Knative UX working group and your experience with Knative Eventing?]
2024-09-15 05:21:04.243 | DEBUG    | pipecat.processors.frame_processor:stop_ttfb_metrics:68 - ElevenLabsTerrify#0 TTFB: 0.7933859825134277
2024-09-15 05:21:13.835 | INFO     | pipecat.transports.services.daily:on_participant_left:462 - Participant left c6d7b05b-2d1e-48bb-a320-5c7437f395d6
INFO:root:Participant left: c6d7b05b-2d1e-48bb-a320-5c7437f395d6
{"timestamp":"2024-09-15T09:21:13.836144Z","level":"ERROR","fields":{"message":"no subscription for consumer: ConsumerId(\"aa7bf10e-e57f-418a-9b85-9e7c41229311\")"},"target":"daily_core::call_manager::events::from_sfu::soup_consumer_closed"}
2024-09-15 05:21:13.836 | INFO     | pipecat.transports.services.daily:leave:336 - Leaving https://cloudsking.daily.co/4XiOvAcNw3fui3Hwwqnz
{"timestamp":"2024-09-15T09:21:13.838829Z","level":"ERROR","fields":{"message":"Mediasoup action clear consumer failed: ConsumerNoLongerExists(ConsumerId(\"aa7bf10e-e57f-418a-9b85-9e7c41229311\"))"},"target":"daily_core::call_manager::mediasoup"}
2024-09-15 05:21:13.847 | INFO     | pipecat.transports.services.daily:leave:345 - Left https://cloudsking.daily.co/4XiOvAcNw3fui3Hwwqnz
2024-09-15 05:21:13.849 | DEBUG    | pipecat.pipeline.runner:run:32 - Runner PipelineRunner#0 finished running PipelineTask#0
Trying to use Groq as base service
Exception ignored in: <function Wave_write.__del__ at 0x1670f0280>
Traceback (most recent call last):
  File "/Users/leoleo/miniforge3/envs/hahaai/lib/python3.10/wave.py", line 326, in __del__
    self.close()
  File "/Users/leoleo/miniforge3/envs/hahaai/lib/python3.10/wave.py", line 447, in close
    self._file.flush()
ValueError: I/O operation on closed file.
